{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Intro to SQL (and BigQuery)\n",
    "- https://www.kaggle.com/learn/intro-to-sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercise: Count, Group By... Having\n",
    "- plus AS: aliasing, Count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "- Queries with GROUP BY can be powerful.\n",
    "- We are going to write queries using GROUP BY to answer questions from de Hacker News dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm\\anaconda3\\envs\\KglSQL_1\\lib\\site-packages\\google\\auth\\_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "C:\\Users\\jm\\AppData\\Local\\Temp\\ipykernel_15032\\4287990220.py:20: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n",
      "  client.list_rows(table, max_results=5).to_dataframe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>dead</th>\n",
       "      <th>by</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>ranking</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I would rather just have wired earbuds, period...</td>\n",
       "      <td>None</td>\n",
       "      <td>zeveb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1591717736</td>\n",
       "      <td>2020-06-09 15:48:56+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>23467666</td>\n",
       "      <td>23456782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNS?</td>\n",
       "      <td>None</td>\n",
       "      <td>nly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1572810465</td>\n",
       "      <td>2019-11-03 19:47:45+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>21436112</td>\n",
       "      <td>21435130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>These benchmarks seem pretty good.  Filterable...</td>\n",
       "      <td>None</td>\n",
       "      <td>mrkeen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1591717727</td>\n",
       "      <td>2020-06-09 15:48:47+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>23467665</td>\n",
       "      <td>23467426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Oh really?&lt;p&gt;* Excel alone uses 86.1MB of priv...</td>\n",
       "      <td>None</td>\n",
       "      <td>oceanswave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1462987532</td>\n",
       "      <td>2016-05-11 17:25:32+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>11677248</td>\n",
       "      <td>11676886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>These systems are useless.  Of the many flaws:...</td>\n",
       "      <td>None</td>\n",
       "      <td>nyxxie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1572810473</td>\n",
       "      <td>2019-11-03 19:47:53+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>21436113</td>\n",
       "      <td>21435025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title   url                                               text  dead  \\\n",
       "0  None  None  I would rather just have wired earbuds, period...  None   \n",
       "1  None  None                                               DNS?  None   \n",
       "2  None  None  These benchmarks seem pretty good.  Filterable...  None   \n",
       "3  None  None  Oh really?<p>* Excel alone uses 86.1MB of priv...  None   \n",
       "4  None  None  These systems are useless.  Of the many flaws:...  None   \n",
       "\n",
       "           by  score        time                 timestamp     type        id  \\\n",
       "0       zeveb    NaN  1591717736 2020-06-09 15:48:56+00:00  comment  23467666   \n",
       "1         nly    NaN  1572810465 2019-11-03 19:47:45+00:00  comment  21436112   \n",
       "2      mrkeen    NaN  1591717727 2020-06-09 15:48:47+00:00  comment  23467665   \n",
       "3  oceanswave    NaN  1462987532 2016-05-11 17:25:32+00:00  comment  11677248   \n",
       "4      nyxxie    NaN  1572810473 2019-11-03 19:47:53+00:00  comment  21436113   \n",
       "\n",
       "     parent  descendants  ranking deleted  \n",
       "0  23456782          NaN      NaN    None  \n",
       "1  21435130          NaN      NaN    None  \n",
       "2  23467426          NaN      NaN    None  \n",
       "3  11676886          NaN      NaN    None  \n",
       "4  21435025          NaN      NaN    None  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fetch the 'full' table from the 'hacker_news' dataset.\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"comments\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"comments\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 1) Prolifict commenters\n",
    "Hacker News would like to send awards to everyone who has written more than 10,000 posts. Write a query that returns all authors (I'll use by column) with more than 10,000 posts as well as their post counts. Call the column with post counts NumPosts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            by  NumPosts\n",
      "0       ncmncm     13621\n",
      "1        pjc50     21417\n",
      "2  dredmorbius     26568\n",
      "3       nradov     13138\n",
      "4      amelius     20985\n"
     ]
    }
   ],
   "source": [
    "# Query to select prolific commenters and post counts\n",
    "prolific_commenters_query = '''\n",
    "    SELECT `by`, COUNT(1) AS NumPosts\n",
    "    FROM `bigquery-public-data.hacker_news.full`\n",
    "    GROUP BY `by`\n",
    "    HAVING COUNT(1) > 10000 ''' \n",
    "# To select a column (or any identifier) that is also a keyword in MySQL,\n",
    "# you need to use backticks around the column name\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(prolific_commenters_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "prolific_commenters = query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(prolific_commenters.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 2) Deleted comments\n",
    "- How many comments have been deleted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   deleted  num_del_comments\n",
      "0     True            968172\n"
     ]
    }
   ],
   "source": [
    "# Query \n",
    "deleted_comments_query = '''\n",
    "    SELECT deleted, SUM(1) AS num_del_comments\n",
    "    FROM `bigquery-public-data.hacker_news.full`\n",
    "    WHERE deleted = True\n",
    "    GROUP BY deleted '''\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(deleted_comments_query, job_config=safe_config)\n",
    "deleted_posts_df = query_job.to_dataframe()\n",
    "print(deleted_posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968172"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_deleted_posts = deleted_posts_df.loc[0, 'num_del_comments']\n",
    "num_deleted_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "You got the right countries. Nice job! Some countries showed up many times in the results. To get each country only once you can run `SELECT DISTINCT country ...`.\n",
    "\n",
    "The DISTINCT keyword ensures each column shows up once, which you'll want in some cases\n",
    "\n",
    "##### Or to get each country just once, you could use\n",
    "``` Python:\n",
    "first_query = '''\n",
    "    SELECT DISTINCT country\n",
    "    FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "    WHERE unit = 'ppm' '''\n",
    "```\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 2) High air quality\n",
    "- Which pollution levels were reported to be exactly 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zero_pollution_query = '''\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "    WHERE value=0 '''\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "zpq_job = client.query(zero_pollution_query, job_config=safe_config)\n",
    "zero_pollution_results = zpq_job.to_dataframe()    # this is my 'df'\n",
    "zero_pollution_results.iloc[[0, 5, 9. -9, -5, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That query wasn't too complicated, and it got the data you want. But these SELECT queries don't organizing data in a way that answers the most interesting questions. For that, we'll need the GROUP BY command.\r\n",
    "\r\n",
    "If you know how to use groupby() in pandas, this is similar. But BigQuery works quickly with far larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 3) JM- Whole table as a DataFrame. Problem with:\n",
    "- `safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.openaq.global_air_quality` '''\n",
    "safe_config = bigquery.QueryJobConfig(maximun_bytes_billed=10**10)\n",
    "query_job = client.query(query, job_config=safe_config)\n",
    "df_whole_table = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole_table.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
